
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<title>CVPR'21 2nd Comprehensive Tutorial on Video Modeling</title>

  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.2.0/css/bootstrap.min.css">
  <link href='http://fonts.googleapis.com/css?family=Lato:400,700' rel='stylesheet' type='text/css'>
  <link href="css/style.css" rel="stylesheet" type="text/css" />
</head>

<body>

<div class="container">
  <table border="0" align="center">
    <tr>
      <td width="700" align="center" valign="middle"><h3>ICCV 2021</h3>
      <span class="title">1st Workshop on Airborne Object Tracking (AOT)</span></td>
    </tr>

    <tr>
        <td colspan="3" align="center"><h3>Virtual<br>DATE TBD</h3></td>
    </tr>
  </table>
</div>

</br>


<div class="container">
  <h2>Speakers</h2>
    <div>
      <div class="instructorwide">
        <a href="https://www.linkedin.com/in/amir-navot-7939101/" >
      <div class="instructorphoto"><img src="figures/placeholder.png"></div>
      <div>Dr. Amir Navot<br>Amazon Prime Air</div>
      </a>
     </div>
    <p>&nbsp;</p>
    </br>
    
      <div class="instructorwide">
          <a href="https://dvl.in.tum.de/team/lealtaixe/" >
        <div class="instructorphoto"><img src="figures/placeholder.png"></div>
        <div>Prof. Laura Leal-Taix√©<br>TU Munich</div>
        </a>
      </div>

      <div class="instructorwide">
        <a href="https://people.epfl.ch/pascal.fua">
            <div class="instructorphoto"><img src="figures/placeholder.png"></div>
            <div>Prof. Pascal Fua<br>EPFL</div>
        </a>
      </div>

      <div class="instructorwide">
        <a href="http://www.cvlibs.net/index.php">
            <div class="instructorphoto"><img src="figures/placeholder.png"></div>
            <div>Prof. Andreas Geiger<br>Tubingen Institute</div>
        </a>
      </div>

      </br>
      <p>&nbsp;</p>


    </div>
    <p></p>
</div>

</br>


<div class="container">
  <h2>Overview</h2>
    <div class="schedule">
        <p> Despite significant advances in Computer Vision, tracking extremely small and far away objects, such as flying Airborne Objects Tracking (AOT) by autonomous flights with Sense and Avoid (SAA) capability, still remains a substantial challenge. Detection, accurate localization and future motion prediction for these objects, which typically cover 0.01% of the image on average, is crucial for the safe navigation of autonomous drones under a wide range of weather and illumination conditions. The 1st Workshop on Airborne Object Tracking will be held virtually on []. This workshop aims at promoting research and closing the gap in performance of state-of-the-art Computer Vision-based models in the domain of airborne objects detection and tracking using monocular visual cameras onboard aerial vehicles.
        </p>

    </div>
</div>

</br>
<div class="container">
  <h2>Call for Papers</h2>
    <div class="schedule">
        <p>Autonomous drones engage Sense and Avoid (SAA) technology for situational awareness and collision avoidance maneuver around unforeseen airborne obstacles on their mission path. Computer Vision models for detection and tracking of Airborne Objects (AO) provide an integral solution that enables the use of low-cost, lightweight cameras onboard these drones for safe navigation. </p>
          
      <p>The domain of Airborne Objects Tracking (AOT), as opposed to the one of traditional computer vision datasets for detection and tracking, poses a unique combination of challenges. This is due to the dynamic nature of the AOs as well as the sensing camera. Moreover, owing to the tiny size (in pixels) of these distant objects, and low density of AOs in the airspace, the data is extremely sparse both spatially and temporally. A large degree of variation in weather conditions, scene illumination, view angle and background terrain add to the complexity of the task. Accurate localization and highly reliable tracking of AOs over several video frames is essential for avoidance maneuver by the drone, when required. Furthermore, for safety and efficiency, it is imperative that the solution produces a very low number of false alarms. Timely detection within a desirable temporal window is essential for generating reliable and informative tracks useful for future motion prediction. Together these conditions pose some novel challenges for training computer vision models on monocular video data for online detection and tracking on AOs. </p>
        
    <p>We invite researchers to submit papers to ICCV presenting their solutions to the Spatio-Temporal Airborne Objects Detection and Tracking problem. The proposed approaches should produce state-of-the-art results on the AOT Challenge dataset under one of the two benchmarks - </p>
        
    <p>1. Airborne detection and tracking - Methods that detect AOs and generate tracks to successfully detect airborne encounters in flight video data while producing a very small number of false alarm rate per hour of flight.</p>
    <p> 2. Frame-level airborne detection - Methods that detect AOs at frame level while producing a very small number of false positives per image. </p>
        
        

    </div>
</div>

<div class="container">
  <h2>Challenge</h2>
    <div class="schedule">
        <p>Please visit <a href="https://www.aicrowd.com/challenges/airborne-object-tracking-challenge/"> this website </a> for more details about Airborne Object Tracking challenge</p>

    </div>
</div>

</br>

<div class="container">
  <h2>Schedule</h2>
    <div class="schedule">
        <p>TBD </p>
        <!-- <p><span class="announce_date">08:45 - 09:30 </span>: <strong> Introduction to Human Activity Understanding in Videos </strong> by Yuanjun Xiong <a href="slide/talk1_activity_understanding_slide.pdf">[slides]</a> <a href="https://youtu.be/Jwt0Wtlv_uo">[talk]</a> </p>
        <p><span class="announce_date">09:30 - 10:10 </span>: <strong> A Chronological Review of Recent SoTA and Beyond </strong> by Yi Zhu <a href="slide/talk2_gluoncv_video_slide.pdf">[slides]</a> <a href="https://youtu.be/Vox_ZnabryQ">[talk]</a> <a href="https://gluon-cv.mxnet.io/model_zoo/action_recognition.html">[GluonCV]</a> </p>
        <p><span class="announce_date">10:10 - 10:30 </span>: <strong> Decord: An Efficient Video Reader for Deep Learning </strong> by Yi Zhu <a href="slide/talk3_decord_slide.pdf">[slides]</a> <a href="https://youtu.be/9uY8IX9IaeQ">[talk]</a> <a href="https://github.com/dmlc/decord/blob/master/examples/video_reader.ipynb">[notebook]</a> </p>
        <p><span class="announce_date">10:30 - 10:45 </span>: <strong> Break </strong> </p>
        <p><span class="announce_date">10:45 - 11:30 </span>: <strong> Deploy Video Models </strong> by Zhi Zhang <a href="slide/talk4_video_deployment_slide.pdf">[slides]</a> <a href="https://youtu.be/KZSmAS9YRIc">[talk]</a> <a href="https://github.com/zhreshold/cvpr2020-videomodeling-deployment">[notebook]</a> </p>
        <p><span class="announce_date">11:30 - 12:15 </span>: <strong> A Journey Through Video Research at AWS </strong> by Joseph Tighe <a href="slide/talk5_video_at_AWS_slide.pdf">[slides]</a> <a href="https://youtu.be/WO6VnAyupbY">[talk]</a> </p>
        <p><span class="announce_date">12:15 - 12:45 </span>: <strong> Structured Representations for Video Understanding </strong> by Chuang Gan <a href="slide/talk6_structured_representation_slide.pdf">[slides]</a> <a href="https://youtu.be/3Cot4dCg_2k">[talk]</a> </p>
 
        <p>For offline Q&A, please post questions to <a href="https://docs.google.com/document/d/1Ngzq5fY7cdwJaZ-VkuMFu3J0H4vh45KNIlLpAw4NGRg/edit?usp=sharing">Google Doc</a></p>
        -->
      </div>
</div>

</br>

<div class="container">
  <h2>Organizers</h2>
    <div>
      <div class="instructor">
          <a href="https://www.linkedin.com/in/maria-zontak-0272135/" >
        <div class="instructorphoto"><img src="figures/placeholder.png"></div>
        <div>Maria Zontak</div>
        </a>
      </div>

      <div class="instructor">
        <a href="https://www.linkedin.com/in/jeanguillaumedurand/">
            <div class="instructorphoto"><img src="figures/placeholder.png"></div>
            <div>Jean-Guillaume Durand</div>
        </a>
      </div>

      <div class="instructor">
        <a href="https://www.linkedin.com/in/tanya-glozman-924ab622/">
            <div class="instructorphoto"><img src="figures/placeholder.png"></div>
            <div>Tanya Glozman</div>
        </a>
      </div>

      <div class="instructor">
        <a href="https://www.linkedin.com/in/yuri-federigi/">
            <div class="instructorphoto"><img src="figures/placeholder.png"></div>
            <div>Yuri Federigi</div>
        </a>
      </div>

      <br>
      <p>&nbsp;</p>
      <div class="instructor">
        <a href="https://www.amazon.science/author/bing-shuai/">
            <div class="instructorphoto"><img src="figures/placeholder.png"></div>
            <div>Bing Shuai</div>
        </a>
      </div>

      <div class="instructor">
        <a href="https://www.linkedin.com/in/arthita-ghosh/">
            <div class="instructorphoto"><img src="figures/placeholder.png"></div>
            <div>Arthita Ghosh</div>
        </a>
      </div>

      <div class="instructor">
        <a href="https://www.linkedin.com/in/david-ferstl-b7890657/">
            <div class="instructorphoto"><img src="figures/placeholder.png"></div>
            <div>David Ferstl</div>
        </a>
      </div>

      <div class="instructor">
        <a href="https://www.linkedin.com/in/christian-leistner-92349583/">
            <div class="instructorphoto"><img src="figures/placeholder.png"></div>
            <div>Christian Leistner</div>
        </a>
      </div>      
      <br>

      <p>&nbsp;</p>

      <div class="instructor">
        <a href="https://bryanyzhu.github.io/">
            <div class="instructorphoto"><img src="figures/placeholder.png"></div>
            <div>Yi Zhu</div>
        </a>
      </div>


    <div class="instructor">
        <a href="https://www.linkedin.com/in/venkysrao/">
      <div class="instructorphoto"><img src="figures/placeholder.png"></div>
      <div>Venky Rao </div>
      </a>
    </div>


      <div class="instructor">
        <a href="https://www.linkedin.com/in/joseph-tighe-4b85001/">
            <div class="instructorphoto"><img src="figures/placeholder.png"></div>
            <div>Joseph Tighe</div>
        </a>
      </div>

      <div class="instructor">
        <a href="https://www.linkedin.com/in/ishay-kamon-455666a5/">
            <div class="instructorphoto"><img src="figures/placeholder.png"></div>
            <div>Ishay Kamon</div>
        </a>
      </div>

      <br>
      <p>&nbsp;</p>  
      <div class="instructor">
        <a href="https://www.linkedin.com/in/amir-navot-7939101/">
            <div class="instructorphoto"><img src="figures/placeholder.png"></div>
            <div>Amir Navot</div>
        </a>
      </div>

    </div>
    <p></p>
</div>

</br>



<div class="containersmall">
<!--     <p>Organizers: Yi Zhu, Zhi Zhang, Yuanjun Xiong and Mu Li</p> -->
    <p>Please contact <a href="mailto:airborne-object-tracking-challenge@amazon.com">Yuri Federigi</a>/<a href="mailto:airborne-object-tracking-challenge@amazon.com">Maria Zontak</a> if you have question.</p>
</div>

</body>
</html>
